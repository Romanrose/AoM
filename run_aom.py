#!/usr/bin/env python
"""
AoM (Aspect-oriented Information for Multimodal Aspect-Based Sentiment Analysis) ä¸»å…¥å£è„šæœ¬
åŸºäºVLP-MABSAæ¡†æ¶æ”¹è¿›ï¼Œæ”¯æŒå¤šæ¨¡æ€æ–¹é¢æƒ…æ„Ÿåˆ†æ
"""

import argparse
import sys
import os
from pathlib import Path

# æ·»åŠ  src ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

from global_var import (
    global_update,
    twitter15_info_path,
    twitter17_info_path,
    trc_info_path,
    bart_model_dir,
    train15_ckpt_dir,
    train17_ckpt_dir,
    train_trc_ckpt_dir,
    twitter15_log_dir,
    twitter17_log_dir,
)


def main():
    parser = argparse.ArgumentParser(
        description='AoM å¤šæ¨¡æ€æ–¹é¢æƒ…æ„Ÿåˆ†ææ¡†æ¶',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
æ”¯æŒçš„çš„ä»»åŠ¡:
  twitter15      - Twitter15 æ•°æ®é›†è®­ç»ƒ (AESCè”åˆä»»åŠ¡)
  twitter17      - Twitter17 æ•°æ®é›†è®­ç»ƒ (AESCè”åˆä»»åŠ¡)
  pretrain_trc   - TRCé¢„è®­ç»ƒä»»åŠ¡
  test           - æµ‹è¯•æ¨¡å¼

ç¤ºä¾‹:
 c
  python run_aom.py --task twitter17 --lr 7.5e-5 --batch_size 16
  python run_aom.py --task pretrain_trc --dataset TRC
  python run_aom.py --task twitter15 --do_test --model_path checkpoints/AoM-ckpt/Twitter2015/AoM.pt
        """
    )

    # ä»»åŠ¡é€‰æ‹©
    parser.add_argument(
        '--task',
        type=str,
        required=True,
        choices=['twitter15', 'twitter17', 'pretrain_trc', 'test'],
        help='é€‰æ‹©è¦è¿è¡Œçš„ä»»åŠ¡'
    )

    # æ·»åŠ é€šç”¨å‚æ•° (è¿™äº›ä¼šä¼ é€’ç»™å…·ä½“çš„è®­ç»ƒè„šæœ¬)
    parser.add_argument(
        '--dataset',
        type=str,
        default=None,
        help='æ•°æ®é›†åç§° (twitter15, twitter17, TRC)'
    )

    parser.add_argument('--lr', type=float, default=7e-5, help='å­¦ä¹ ç‡')
    parser.add_argument('--batch_size', type=int, default=16, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--epochs', type=int, default=35, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--gpu_num', type=int, default=1, help='GPUæ•°é‡')
    parser.add_argument('--rank', type=int, default=0, help='GPUæ’å (0-7)')
    parser.add_argument('--no_train', action='store_true', help='åªæµ‹è¯•ï¼Œä¸è®­ç»ƒ')
    parser.add_argument('--do_test', action='store_true', help='æµ‹è¯•æ¨¡å¼')

    # æ·»åŠ å…¶ä»–å¸¸ç”¨å‚æ•°
    parser.add_argument('--warmup', type=float, default=0.1, help='é¢„çƒ­æ­¥æ•°æ¯”ä¾‹')
    parser.add_argument('--grad_clip', type=float, default=5.0, help='æ¢¯åº¦è£å‰ª')
    parser.add_argument('--seed', type=int, default=66, help='éšæœºç§å­')
    parser.add_argument('--model_config', type=str, default='configs/pretrain_base.json', help='æ¨¡å‹é…ç½®')
    parser.add_argument('--log_dir', type=str, default='logs', help='æ—¥å¿—ç›®å½•')

    # é¢„è®­ç»ƒç›¸å…³
    parser.add_argument('--trc_pretrain_file', type=str,  default='checkpoints/pytorch_model.bin', help='TRCé¢„è®­ç»ƒæ¨¡å‹è·¯å¾„')

    # æµ‹è¯•ç›¸å…³
    parser.add_argument('--model_path', type=str, help='æµ‹è¯•ç”¨çš„æ¨¡å‹è·¯å¾„')
    parser.add_argument('--checkpoint_dir', type=str, default='checkpoints', help='æ£€æŸ¥ç‚¹ç›®å½•')

    # è§£æå‚æ•°
    args = parser.parse_args()

    # æ›´æ–°å…¨å±€å˜é‡
    args = global_update(args)

    # æ„å»ºMAESC_training.pyçš„å‚æ•°åˆ—è¡¨
    cmd_args = ['python', str(Path(__file__).parent / 'MAESC_training.py')]

    # æ ¹æ®ä»»åŠ¡è®¾ç½®datasetå’Œè·¯å¾„ï¼ˆç¬¦åˆåŸå§‹AoMè®¾è®¡ï¼‰
    if args.task == 'twitter15':
        if not args.dataset:
            args.dataset = 'twitter15'
        cmd_args.extend(['--dataset', 'twitter15', twitter15_info_path])
        cmd_args.extend(['--checkpoint_dir', train15_ckpt_dir])
        # ç»Ÿä¸€æ—¥å¿—ç›®å½•åˆ° logs/ ä¸‹
        if args.log_dir == 'logs':  # åªæœ‰åœ¨æœªè‡ªå®šä¹‰æ—¶æ‰ä½¿ç”¨é»˜è®¤å€¼
            args.log_dir = twitter15_log_dir
    elif args.task == 'twitter17':
        if not args.dataset:
            args.dataset = 'twitter17'
        cmd_args.extend(['--dataset', 'twitter17', twitter17_info_path])
        cmd_args.extend(['--checkpoint_dir', train17_ckpt_dir])
        # ç»Ÿä¸€æ—¥å¿—ç›®å½•åˆ° logs/ ä¸‹
        if args.log_dir == 'logs':  # åªæœ‰åœ¨æœªè‡ªå®šä¹‰æ—¶æ‰ä½¿ç”¨é»˜è®¤å€¼
            args.log_dir = twitter17_log_dir
    elif args.task == 'pretrain_trc':
        if not args.dataset:
            args.dataset = 'TRC'
        cmd_args.extend(['--dataset', 'TRC', trc_info_path])
        cmd_args.extend(['--checkpoint_dir', train_trc_ckpt_dir])
        # TRCé¢„è®­ç»ƒä½¿ç”¨é»˜è®¤log_dir

    # æ·»åŠ å…¶ä»–å‚æ•°
    cmd_args.extend([
        '--model_config', args.model_config,
        '--log_dir', args.log_dir,
        '--lr', str(args.lr),
        '--batch_size', str(args.batch_size),
        '--epochs', str(args.epochs),
        '--warmup', str(args.warmup),
        '--grad_clip', str(args.grad_clip),
        '--seed', str(args.seed),
        '--gpu_num', str(args.gpu_num),
        '--rank', str(args.rank),
        '--trc_pretrain_file', args.trc_pretrain_file,
        '--bart_model', bart_model_dir,
        '--nn_attention_on',
        '--nn_attention_mode', '0',
        '--trc_on',
        '--gcn_on',
        '--dep_mode', '2',
        '--sentinet'
    ])

    # æµ‹è¯•æ¨¡å¼
    if args.no_train:
        cmd_args.append('--no_train')

    if args.do_test and args.model_path:
        cmd_args.extend(['--do_test', '--model_path', args.model_path])

    # === GPUè®¾å¤‡æ£€æŸ¥ ===
    import torch
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        print(f"\n{'='*60}")
        print(f"GPUç¯å¢ƒæ£€æŸ¥:")
        print(f"  PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"  CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"  å¯ç”¨GPUæ•°é‡: {gpu_count}")
        for i in range(gpu_count):
            print(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
        print(f"{'='*60}\n")

        # æ£€æŸ¥rankå‚æ•°
        if args.rank >= gpu_count:
            print(f"âš ï¸  è­¦å‘Š: rank={args.rank} è¶…å‡ºGPUæ•°é‡({gpu_count})ï¼Œè‡ªåŠ¨è°ƒæ•´ä¸º0")
            args.rank = 0
            cmd_args[cmd_args.index('--rank') + 1] = '0'  # æ›´æ–°å‘½ä»¤ä¸­çš„rankå€¼
            print(f"âœ… å·²å°†rankè°ƒæ•´ä¸º: {args.rank}\n")
        else:
            print(f"âœ… ä½¿ç”¨GPU {args.rank}: {torch.cuda.get_device_name(args.rank)}\n")
    else:
        print("âš ï¸  GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUè®­ç»ƒ\n")

    # æ‰“å°å‘½ä»¤
    print("=" * 80)
    print("ğŸš€ Running AoM Training:")
    print("=" * 80)
    print("Task:", args.task)
    print("Dataset:", args.dataset)
    print("Command:", ' '.join(cmd_args))
    print("=" * 80)

    # æ‰§è¡Œå‘½ä»¤
    os.system(' '.join(cmd_args))


if __name__ == '__main__':
    main()
