# AoMé¡¹ç›®æ•°æ®ç»´åº¦å˜åŒ–æµç¨‹åˆ†æ

> æŒ‰ç…§ä»£ç æ‰§è¡Œé¡ºåºï¼Œè¯¦ç»†åˆ†ææ•°æ®åœ¨å„æ¨¡å—é—´çš„ç»´åº¦å˜æ¢ã€‚

---

## ğŸ“Š æ•°æ®æµæ€»è§ˆ

### è¾“å…¥æ•°æ®ç»“æ„
```
Batchæ•°æ® (batch_size=B):
â”œâ”€â”€ input_ids: [B, 66]              # 51å›¾åƒtoken + 15æ–‡æœ¬token
â”œâ”€â”€ image_features: [B, 51, 2048]   # 51ä¸ªå›¾åƒROIç‰¹å¾ï¼Œ2048ç»´
â”œâ”€â”€ labels: [B, target_len]         # ç›®æ ‡åºåˆ—æ ‡ç­¾
â””â”€â”€ attention_mask: [B, 66]         # æ³¨æ„åŠ›æ©ç 
```

---

## ä¸€ã€æ•°æ®åŠ è½½é˜¶æ®µ

### 1.1 æ‰¹æ¬¡æ•°æ®å‡†å¤‡
**ä½ç½®**: `dataset.py: __getitem__`

```python
def __getitem__(self, index):
    return {
        'input_ids': torch.tensor(input_ids, dtype=torch.long),           # [66]
        'image_features': image_features,                                  # [51, 2048]
        'labels': torch.tensor(labels, dtype=torch.long),                 # [target_len]
        'mask': torch.tensor(mask, dtype=torch.long),                     # [66]
    }
```

**ç»´åº¦å˜åŒ–**:
```
å•ä¸ªæ ·æœ¬ â†’ æ‰¹æ¬¡ (B=16)
input_ids: [66] â†’ [B, 66]
image_features: [51, 2048] â†’ [B, 51, 2048]
labels: [target_len] â†’ [B, target_len]
mask: [66] â†’ [B, 66]
```

---

## äºŒã€ç¼–ç å™¨é˜¶æ®µ (BART Encoder)

### 2.1 å¤šæ¨¡æ€ç‰¹å¾åµŒå…¥
**ä½ç½®**: `src/model/modules.py: 83-94` (_embed_multi_modal)

```python
# å›¾åƒç‰¹å¾åµŒå…¥
embedded_images = self.embed_images(image_features)  # Linear(2048â†’768)
# [B, 51, 2048] â†’ [B, 51, 768]

# æ–‡æœ¬tokenåµŒå…¥
embedded = self.embed_tokens(input_ids)
# [B, 66] â†’ [B, 66, 768]

# å¤šæ¨¡æ€èåˆ
for index, value in enumerate(embedded_images):
    if len(value) > 0:
        embedded[index, mask[index]] = value
# å°†å›¾åƒç‰¹å¾åµŒå…¥åˆ°å¯¹åº”ä½ç½®
# embedded: [B, 66, 768]
```

**ç»´åº¦å˜åŒ–**:
```
è¾“å…¥:
â”œâ”€â”€ image_features: [B, 51, 2048]
â””â”€â”€ input_ids: [B, 66]

è¾“å‡º: embedded: [B, 66, 768]
```

### 2.2 BARTç¼–ç å™¨è¾“å‡º
**ä½ç½®**: `src/model/modules.py: 130-149`

```python
# Transformerç¼–ç 
x = x.transpose(0, 1)  # [B, 66, 768] â†’ [66, B, 768]

for encoder_layer in self.layers:
    x, attn = encoder_layer(x, attention_mask, output_attentions=output_attentions)

encoder_outputs = x.transpose(0, 1)  # [66, B, 768] â†’ [B, 66, 768]
```

**ç»´åº¦å˜åŒ–**:
```
è¾“å…¥: embedded: [B, 66, 768]
è¾“å‡º: encoder_outputs: [B, 66, 768] (æœ€ç»ˆç¼–ç ç»“æœ)
```

---

## ä¸‰ã€AÂ³Mæ¨¡å— (è¯­ä¹‰å¯¹é½)

### 3.1 åè¯ç‰¹å¾æå–
**ä½ç½®**: `MAESC_model.py: 141-159` (get_noun_embed)

```python
noun_embed = torch.zeros(feature.shape[0], max_noun_num, feature.shape[-1]).to(self.mydevice)
# feature: [B, 66, 768]
# noun_embed: [B, L, 768]  (L = max_noun_num)

for i in range(len(feature)):
    noun_embed[i] = torch.index_select(feature[i], dim=0, index=noun_position[i])
    # ä»66ä¸ªtokenä¸­æå–åè¯ä½ç½®çš„ç‰¹å¾
```

**ç»´åº¦å˜åŒ–**:
```
è¾“å…¥:
â”œâ”€â”€ encoder_outputs: [B, 66, 768]
â””â”€â”€ noun_mask: [B, 66] (æ ‡è¯†åè¯ä½ç½®)

è¾“å‡º: noun_embed: [B, L, 768]  (L â‰ˆ 5-10)
```

### 3.2 æ³¨æ„åŠ›è®¡ç®— (mode='cat')
**ä½ç½®**: `MAESC_model.py: 207-222`

#### æ­¥éª¤1: ç‰¹å¾æ‰©å±•
```python
multi_features_rep = encoder_outputs.unsqueeze(2).repeat(1, 1, noun_embed.shape[1], 1)
# [B, 66, 768] â†’ [B, 66, 1, 768] â†’ [B, 66, L, 768]

noun_features_rep = noun_embed.unsqueeze(1).repeat(1, encoder_outputs.shape[1], 1, 1)
# [B, L, 768] â†’ [B, 1, L, 768] â†’ [B, 66, L, 768]
```

#### æ­¥éª¤2: çº¿æ€§å˜æ¢
```python
noun_features_rep = self.noun_linear(noun_features_rep)  # W_CA
multi_features_rep = self.multi_linear(multi_features_rep)  # W_H
# ç»´åº¦ä¸å˜: [B, 66, L, 768]
```

#### æ­¥éª¤3: ç‰¹å¾æ‹¼æ¥
```python
concat_features = torch.tanh(torch.cat([noun_features_rep, multi_features_rep], dim=-1))
# [B, 66, L, 768] + [B, 66, L, 768] â†’ [B, 66, L, 1536]
```

#### æ­¥éª¤4: æ³¨æ„åŠ›æƒé‡
```python
att = torch.softmax(self.att_linear(concat_features).squeeze(-1), dim=-1)
# concat_features: [B, 66, L, 1536] â†’ att_linear â†’ [B, 66, L, 1]
# softmax â†’ [B, 66, L]
```

#### æ­¥éª¤5: æ–¹é¢ç‰¹å¾
```python
att_features = torch.matmul(att, noun_embed)
# [B, 66, L] @ [B, L, 768] â†’ [B, 66, 768]
```

#### æ­¥éª¤6: èåˆç³»æ•°
```python
alpha = torch.sigmoid(self.linear(
    torch.cat([self.alpha_linear1(encoder_outputs),
               self.alpha_linear2(att_features)], dim=-1)))
# encoder_outputs: [B, 66, 768]
# alpha_linear1/2: â†’ [B, 66, 768] each
# concat: [B, 66, 1536]
# linear: [1, 1536] â†’ [B, 66, 1]
# sigmoid â†’ [B, 66, 1]

alpha = alpha.repeat(1, 1, 768)  # å¹¿æ’­
# [B, 66, 1] â†’ [B, 66, 768]
```

#### æ­¥éª¤7: æœ€ç»ˆå¯¹é½ç‰¹å¾
```python
encoder_outputs = torch.mul(1-alpha, encoder_outputs) + torch.mul(alpha, att_features)
# (1-Î±) Ã— h_t + Î± Ã— h_t^A
# [B, 66, 768] = Ä¥_t (AÂ³Mè¾“å‡º)
```

**å®Œæ•´AÂ³Mæ•°æ®ç»´åº¦æµ**:
```
è¾“å…¥: encoder_outputs: [B, 66, 768]
      noun_embed: [B, L, 768]

æµç¨‹:
1. ç‰¹å¾æ‰©å±• â†’ [B, 66, L, 768]
2. çº¿æ€§å˜æ¢ â†’ [B, 66, L, 768]
3. ç‰¹å¾æ‹¼æ¥ â†’ [B, 66, L, 1536]
4. æ³¨æ„åŠ›æƒé‡ â†’ [B, 66, L]
5. æ–¹é¢ç‰¹å¾ â†’ [B, 66, 768]
6. èåˆç³»æ•° â†’ [B, 66, 1] â†’ [B, 66, 768]
7. æœ€ç»ˆè¾“å‡º â†’ [B, 66, 768] = Ä¥_t
```

---

## å››ã€AG-GCNæ¨¡å— (æƒ…æ„Ÿèšåˆ)

### 4.1 ç‰¹å¾åˆ†ç¦»
**ä½ç½®**: `MAESC_model.py: 249-250`

```python
img_feature = encoder_outputs[:, :51, :]  # [B, 51, 768]
text_feature = encoder_outputs[:, 51:, :]  # [B, 15, 768]
```

**ç»´åº¦å˜åŒ–**:
```
è¾“å…¥: encoder_outputs: [B, 66, 768] = Ä¥_t

è¾“å‡º:
â”œâ”€â”€ img_feature: [B, 51, 768]  # å›¾åƒç‰¹å¾
â””â”€â”€ text_feature: [B, 15, 768]  # æ–‡æœ¬ç‰¹å¾
```

### 4.2 ä¾èµ–çŸ©é˜µæ„å»º
**ä½ç½®**: `MAESC_model.py: 248`

```python
new_dependency_matrix = torch.zeros([B, 66, 66], dtype=torch.float).to(encoder_outputs.device)
# [B, 66, 66] (åˆ†å—çŸ©é˜µD)
```

### 4.3 æ–‡æœ¬-æ–‡æœ¬ä¾èµ–
**ä½ç½®**: `MAESC_model.py: 281-284`

```python
text_feature_extend1 = text_feature.unsqueeze(1).repeat(1, 15, 1, 1)
text_feature_extend2 = text_feature.unsqueeze(2).repeat(1, 1, 15, 1)
text_sim = torch.cosine_similarity(text_feature_extend1, text_feature_extend2, dim=-1)
# [B, 15, 768] â†’ [B, 15, 15, 768] (æ‰©å±•)
# ä½™å¼¦ç›¸ä¼¼åº¦ â†’ text_sim: [B, 15, 15]

new_dependency_matrix[:, 51:, 51:] = dependency_matrix * text_sim
# [B, 15, 15] (å¡«å…¥D_TTå­çŸ©é˜µ)
```

### 4.4 å›¾åƒ-æ–‡æœ¬ä¾èµ–
**ä½ç½®**: `MAESC_model.py: 270-278`

```python
img_feature_extend = img_feature.unsqueeze(2).repeat(1, 1, text_feature.shape[1], 1)
text_feature_extend = text_feature.unsqueeze(1).repeat(1, img_feature.shape[1], 1, 1)
sim = torch.cosine_similarity(img_feature_extend, text_feature_extend, dim=-1)
# [B, 51, 768] & [B, 15, 768] â†’ [B, 51, 15, 768]
# ä½™å¼¦ç›¸ä¼¼åº¦ â†’ sim: [B, 51, 15]

noun_mask = noun_mask[:, 51:].unsqueeze(1).repeat(1, sim.shape[1], 1)
sim = sim * noun_mask  # ä»…ä¿ç•™åè¯ç›¸å…³

new_dependency_matrix[:, :51, 51:] = sim  # D_VT
new_dependency_matrix[:, 51:, :51] = torch.transpose(sim, 1, 2)  # D_TV
# [B, 51, 15] & [B, 15, 51]
```

**ä¾èµ–çŸ©é˜µç»´åº¦å˜åŒ–**:
```
è¾“å…¥:
â”œâ”€â”€ text_feature: [B, 15, 768]
â””â”€â”€ img_feature: [B, 51, 768]

æ–‡æœ¬ä¾èµ–:
text_sim: [B, 15, 15] â†’ D_TT: [B, 15, 15]

å›¾åƒä¾èµ–:
sim: [B, 51, 15] â†’ D_VT: [B, 51, 15]
                     D_TV: [B, 15, 51]

æœ€ç»ˆ: D: [B, 66, 66] = [[D_VV, D_VT], [D_TV, D_TT]]
```

### 4.5 æƒ…æ„Ÿç‰¹å¾å¤„ç†
**ä½ç½®**: `MAESC_model.py: 294-298`

```python
sentiment_value = nn.ZeroPad2d(padding=(51, 0, 0, 0))(sentiment_value)
# [B, 15] â†’ [B, 66]

sentiment_value = sentiment_value.unsqueeze(-1)
# [B, 66] â†’ [B, 66, 1]

sentiment_feature = self.senti_value_linear(sentiment_value)
# [B, 66, 1] â†’ senti_value_linear â†’ [B, 66, 768] = s_i
```

**ç»´åº¦å˜åŒ–**:
```
è¾“å…¥: sentiment_value: [B, 15] (SenticNetåˆ†æ•°)

æµç¨‹:
1. ZeroPad2d â†’ [B, 66]
2. unsqueeze â†’ [B, 66, 1]
3. Linear â†’ [B, 66, 768] = s_i
```

### 4.6 æƒ…æ„Ÿ-è¯­ä¹‰èåˆ
**ä½ç½®**: `MAESC_model.py: 298`

```python
context_feature = self.context_linear(encoder_outputs + sentiment_feature)
# [B, 66, 768] + [B, 66, 768] â†’ [B, 66, 768]
# Linear â†’ [B, 66, 768] = h_i^S
```

### 4.7 å›¾å·ç§¯è®¡ç®— (GCN)
**ä½ç½®**: `MAESC_model.py: 299` + `GCN.py`

```python
context_feature = self.context_gcn(context_feature, context_dependency_matrix, attention_mask)

# GCNå†…éƒ¨:
def forward(self, inputs, adj, mask=None):
    # inputs: [B, 66, 768] = h_{i,l-1}^S
    # adj: [B, 66, 66] = A (å…³è”çŸ©é˜µ)

    support = torch.matmul(inputs, self.weight)
    # [B, 66, 768] @ [768, 768] â†’ [B, 66, 768]

    output = torch.matmul(adj, support)
    # [B, 66, 66] @ [B, 66, 768] â†’ [B, 66, 768]

    output = self.act(output + self.bias)  # ReLU
    return output
```

**ç»´åº¦å˜åŒ–**:
```
è¾“å…¥:
â”œâ”€â”€ context_feature: [B, 66, 768] = h_{i,l-1}^S
â””â”€â”€ context_dependency_matrix: [B, 66, 66] = A

GCNè®¡ç®—:
support: [B, 66, 768]
â†’ output: [B, 66, 768] = h_{i,l}^S

è¾“å‡º: GCN_output: [B, 66, 768] = Ä¤^S
```

### 4.8 æœ€ç»ˆèåˆ
**ä½ç½®**: `MAESC_model.py: 302`

```python
mix_feature = self.gcn_proportion * context_feature + encoder_outputs
# gcn_proportion = 0.5 (é»˜è®¤)
# 0.5 Ã— Ä¤^S + 1.0 Ã— Ä¤ = HÌƒ
```

**ç»´åº¦å˜åŒ–**:
```
è¾“å…¥:
â”œâ”€â”€ context_feature (GCN): [B, 66, 768] = Ä¤^S
â””â”€â”€ encoder_outputs: [B, 66, 768] = Ä¤

èåˆ: 0.5 Ã— [B, 66, 768] + 1.0 Ã— [B, 66, 768] â†’ [B, 66, 768]

è¾“å‡º: mix_feature: [B, 66, 768] = HÌƒ (AG-GCNè¾“å‡º)
```

---

## äº”ã€è§£ç å™¨é˜¶æ®µ (BART Decoder)

### 5.1 è§£ç å™¨å‰å‘ä¼ æ’­
**ä½ç½®**: `src/model/modules.py: 237-243`

```python
dict = self.decoder(
    input_ids=tokens,
    encoder_hidden_states=mix_feature,  # [B, 66, 768]
    encoder_padding_mask=encoder_pad_mask,
    decoder_padding_mask=decoder_pad_mask,
    decoder_causal_mask=self.causal_masks[:tokens.size(1), :tokens.size(1)],
    return_dict=True)

hidden_state = dict.last_hidden_state
# [B, tgt_len, 768] = h_t^d
```

**ç»´åº¦å˜åŒ–**:
```
è¾“å…¥:
â”œâ”€â”€ tokens: [B, tgt_len] (ç›®æ ‡åºåˆ—)
â”œâ”€â”€ mix_feature (encoderè¾“å‡º): [B, 66, 768] = HÌƒ
â”œâ”€â”€ encoder_pad_mask: [B, 66]
â””â”€â”€ decoder_pad_mask: [B, tgt_len]

BART Decoderè¾“å‡º:
hidden_state: [B, tgt_len, 768] = h_t^d
```

---

## å…­ã€é¢„æµ‹è¾“å‡ºé˜¶æ®µ

### 6.1 æƒ…æ„Ÿåˆ†ç±»
**ä½ç½®**: `src/model/modules.py: 273-278`

```python
tag_scores = F.linear(
    hidden_state,
    self.dropout_layer(
        self.decoder.embed_tokens.weight[self.label_start_id:self.label_start_id + 3]))
# hidden_state: [B, tgt_len, 768]
# embed_tokens.weight[label]: [3, 768] (POS, NEU, NEG)
# F.linear: [B, tgt_len, 768] @ [3, 768]^T â†’ [B, tgt_len, 3]

logits[:, :, 3:self.src_start_index] = tag_scores
# logits: [B, tgt_len, num_classes] = P(y_t)
```

**ç»´åº¦å˜åŒ–**:
```
è¾“å…¥:
â”œâ”€â”€ hidden_state: [B, tgt_len, 768] = h_t^d
â””â”€â”€ label_embeddings: [3, 768] (POS, NEU, NEG)

è®¡ç®—: [B, tgt_len, 768] @ [3, 768]^T â†’ [B, tgt_len, 3]

è¾“å‡º: logits: [B, tgt_len, num_classes] = P(y_t)
     å…¶ä¸­æƒ…æ„Ÿç±»åˆ«: POS(0), NEU(1), NEG(2)
```

---

## ä¸ƒã€å®Œæ•´æ•°æ®æµæ€»ç»“

### å®Œæ•´ç»´åº¦å˜åŒ–é“¾

```
è¾“å…¥æ‰¹æ¬¡ (B=16):
â”œâ”€â”€ input_ids: [B, 66]
â”œâ”€â”€ image_features: [B, 51, 2048]
â””â”€â”€ labels: [B, tgt_len]

    â†“ [ç¼–ç å™¨]
encoder_outputs: [B, 66, 768]

    â†“ [AÂ³Mæ¨¡å—]
noun_embed: [B, L, 768]
â†’ att: [B, 66, L]
â†’ att_features: [B, 66, 768]
â†’ alpha: [B, 66, 768]
â†’ Ä¥_t: [B, 66, 768]

    â†“ [AG-GCNæ¨¡å—]
img_feature: [B, 51, 768]
text_feature: [B, 15, 768]
â†’ sim: [B, 51, 15]
â†’ dependency_matrix: [B, 66, 66]
â†’ sentiment_feature: [B, 66, 768]
â†’ GCN_output: [B, 66, 768] = Ä¤^S
â†’ HÌƒ: [B, 66, 768]

    â†“ [è§£ç å™¨]
hidden_state: [B, tgt_len, 768] = h_t^d

    â†“ [é¢„æµ‹è¾“å‡º]
logits: [B, tgt_len, num_classes] = P(y_t)
```

### å…³é”®ç»´åº¦å¸¸æ•°

| ç»´åº¦åç§° | å€¼ | è¯´æ˜ |
|----------|----|----|
| B | 16 | æ‰¹æ¬¡å¤§å° |
| seq_len | 66 | è¾“å…¥åºåˆ—æ€»é•¿åº¦ |
| img_len | 51 | å›¾åƒtokenæ•°é‡ |
| text_len | 15 | æ–‡æœ¬tokenæ•°é‡ |
| img_feat_dim | 2048 | å›¾åƒROIç‰¹å¾ç»´åº¦ |
| hidden_dim | 768 | æ–‡æœ¬/éšè—å±‚ç»´åº¦ |
| noun_len | L | åè¯æ•°é‡ (åŠ¨æ€) |
| tgt_len | 10 | ç›®æ ‡åºåˆ—é•¿åº¦ |
| num_classes | 50265 | è¾“å‡ºç±»åˆ«æ•° |

### å…³é”®å¼ é‡æ“ä½œ

| æ“ä½œ | è¾“å…¥ç»´åº¦ | è¾“å‡ºç»´åº¦ | è¯´æ˜ |
|------|----------|----------|------|
| `unsqueeze` | `[B, N]` | `[B, 1, N]` | æ‰©å±•ç»´åº¦ |
| `repeat` | `[B, N]` | `[B, L, N]` | é‡å¤æ•°æ® |
| `matmul` | `[B, N, M] @ [B, M, K]` | `[B, N, K]` | æ‰¹é‡çŸ©é˜µä¹˜ |
| `cosine_similarity` | `[B, N, D], [B, M, D]` | `[B, N, M]` | ä½™å¼¦ç›¸ä¼¼åº¦ |
| `torch.cat` | `[B, N, D], [B, N, D]` | `[B, N, 2D]` | ç»´åº¦æ‹¼æ¥ |
| `Linear` | `[B, N, D_in]` | `[B, N, D_out]` | çº¿æ€§å˜æ¢ |
| `softmax` | `[B, N]` | `[B, N]` | å½’ä¸€åŒ– |

---

**åˆ†æå®Œæˆæ—¶é—´**: 2025-11-13
**æ•°æ®æµå®Œæ•´æ€§**: âœ…